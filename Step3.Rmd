---
title: "Step3_test"
author: "Annie Kellner"
date: "2023-02-07"
output: html_document
---

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # 'echo' means R will print the code along with the results. 

rm(list = ls()) # clear workspace

library(terra)
library(sf)
library(dplyr)
library(stringr)
library(data.table)
library(tidyr)
library(viridis)
library(mapview)
library(raster)

source('./Code/CEMML/Misc/character_vectors.R')

```

# *PART ONE: User settings - choose AFB, model, scenarios, years of interest*

First, let's select which of the `models` you'd like to run. Highlight the word `models` and click 'Run' at the top right (or use the shortcut *Ctrl + Enter*). The available models correspond to numbers in the vector (e.g., HADGEM2-ES is [1]). 

In the code chunk below, enter the number between the brackets ([]) that corresponds with your model of interest. Then let's see what scenarios and variables are available for that model.

```{r enter-afb-and-model}

AFB_Name <- "Homestead_ARB" # Can create a vector similar to 'models' above if desired

model <- models[2] 

model_dir <- paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = "")
scenario_dirs <- list.dirs(path = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = ""), full.names = FALSE)

cat(paste("The model you have selected is", model, "and the AFB is", AFB_Name))

```

The next chunk checks what scenarios (subfolders) are contained in the 'Data' folder associated with the model of interest.

```{r results='asis'}

cat("The scenarios (subfolders) associated with this model are:", sep = '\n') # cat() basically means 'print' in this context 
cat(paste("-", scenario_dirs), sep = "\n") # names into separate lines for readability ('\n' = line)

```

*Enter the scenarios of interest below:*

```{r enter-scenarios}

scenario1 <- "historical"
scenario2 <- "rcp45"
scenario3 <- "rcp85"

```

Next, let's see which variables are represented in this dataset

```{r}

example_dir = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, "\\", scenario1, sep = "")
example_filenames <- list.files(example_dir, pattern = '.nc', full.names = FALSE) # this line might need to be adjusted if some files are .ncdf or other

variables <- unique(substr(example_filenames, 1,6)) # Numbers 1 and 6 refer to character indices within the file names (i.e., the first six letters of the file name)

cat("The variables in this dataset are:", sep = '\n')
cat(paste("-", variables), sep = "\n")

```

```{r enter-years-of-interest}

historical_start_year <- 1976 # Start year of interest for the historical time period  
historical_end_year <- 2005 # End year of interest for the historical time period

future1_start_year <- 2026 # Start year of interest for the first future time period 
future1_end_year <- 2035 # End year of interest for the first future time period 

future2_start_year <- 2046 # Start year of interest for the second future time period 
future2_end_year <- 2055 # End year of interest for the second future time period 

```

####################################################################################################
# THIS CONCLUDES THE USER SETTINGS PORTION OF THE SCRIPT

DT <- data.table(histFileNames_var1, result = grepl(pattern, histFileNames_var1))  
histDT_var1 <- DT %>% filter(result == TRUE) # spot check the number of observations - should equal the number of years in the time period of interest

# Check to see that files look right and nothing weird made it into the list

histFileNames_var1 <- histDT_var1$histFileNames_var1 # turn data.frame column into a vector for use with rast()

histFileNames_var1

# *PART TWO: Let 'er Rip!*


```{r directories, echo=FALSE}

dir_netcdfs = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = "")

dir_installation_boundaries <- "N:\\RStor\\mindyc\\afccm\\AF_CIP_ENV_Data_Phase3/Installation_Boundaries/" # site boundary shape files used for clipping


# The last two are straight from the original script. Will change so that directories can be set more generally in 'settings'

#dir_output_csvs = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Results_LOCA_V2" # output csv

#dir_functions = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Software Apps\\R scripts\\LOCA_V2" # scripts that call in functions for analysis

```

```{r create-array}

# Not sure if this only applies to LOCA, as comment implies. Can cross that bridge when we come to it. 

scenario_yr_array = array(1:15, dim=c(5,3))

scenario_yr_array[1,1:3] = c("historical", historical_start_year, historical_end_year)
scenario_yr_array[2,1:3] = c("rcp45", future1_start_year, future1_end_year)
scenario_yr_array[3,1:3] = c("rcp45", future2_start_year, future2_end_year)
scenario_yr_array[4,1:3] = c("rcp85", future1_start_year, future1_end_year)
scenario_yr_array[5,1:3] = c("rcp85", future2_start_year, future2_end_year)

```


```{r historical-files-variable1}

histFileNames_var1 <- list.files(dir_historical_ncdfs, pattern = variables[1], full.names = TRUE) # partition files by variable

pattern <- paste(seq(scenario_yr_array[1,2], scenario_yr_array[1,3], 1), collapse = "|") # partition by years of interest

DT <- data.table(histFileNames_var1, result = grepl(pattern, histFileNames_var1))  
histDT_var1 <- DT %>% filter(result == TRUE) # spot check the number of observations - should equal the number of years in the time period of interest

# Check to see that files look right and nothing weird made it into the list

histFileNames_var1 <- histDT_var1$histFileNames_var1 # turn data.frame column into a vector for use with rast()

histFileNames_var1
```

# *SPATIAL ANALYSIS*

First, let's do a gut check to make sure the spatial files are where they should be. The map will appear below the code chunk, and you can zoom in as needed to view small AFB's 

```{r gut-check-location}

# Rasters

rHistVar1 <- rast(histFileNames_var1) # multilayered raster for analysis

rx <- raster(rHistVar1[[1]]) # Single layer raster for plotting (first layer)

# AFB

afb_dir <- (paste(dir_installation_boundaries, AFB_Name, sep = '/'))

afbSF <- st_read(paste(afb_dir, '.shp', sep = "")) # read in using sf package first
afbSF <- sf::st_as_sf(afbSF, coords = c("longitude", "latitude"), crs = st_crs(4326)) # EPSG:4326 is lat/long

afb <- vect(afbSF) # for use with terra package

# Quick plot

mapview(rx, col.regions = hcl.colors(5, palette = "viridis", alpha = 0.8)) + # 5 i an ab
  mapview(afbSF, col.regions = "black")


```

We should also check the size of the AFB to see whether we should use the centroid or multiple cells for analysis. 

```{r decision-to-use-shp-or-centroid}

# What is the cell size of the ncdf?

rx <- rast(rx) # convert to terra object because estimation is better. Could also use raster::area()
rxCrop <- terra::crop(rx, afb)
rxCell <- cellSize(rxCrop, unit = "km")
ncdf_cellSize <- mean(values(rxCell)) # get mean cell size of ncdf


# How big is the AFB?

afb_area <- expanse(afb, unit = "km")

# add an if_else statement to tell R whether to extract raster values from matrix or shapefile
m <- data.frame(x = afb$longitude, y = afb$latitude) # matrix with longitude and latitude pulled from shp metadata

#extractObj <- if_else(afb_area < ncdf_cellSize, m, afb)

#if_else(, extr = m, extr = afb)

```

The area covered by each raster cell (that overlays the AFB) is `ncdf_cellSize` km^2^ and the area of the AFB is `afb_area` km^2^.

```{r extract-values}

test <- terra::extract(rHistVar1, m)

piv <- test %>%
  pivot_longer(cols = starts_with(variables[1]),
               names_to = "Layer",
               names_prefix = variables[1],
               values_to = variables[1],
               values_drop_na = FALSE)

#saveRDS(piv, file = './Data/Derived/pr_test.Rds')

```

```{r unit-conversion}

piv2 <- pr_test %>%
  mutate(PPT_mm = pr*86400) # From RasterUnitConvert function

```

```{r check-results}

# Bring in results 

avdf <- read_csv('./Results/allvaluesdf.Rds')


piv2$Compare <- results$PPT_mm

piv2$Diff <- piv2$PPT_mm - piv2$Compare

sum(piv2$Diff)

```












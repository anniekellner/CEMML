---
title: "Step3_test"
author: "Annie Kellner"
date: "2023-02-07"
output: html_document
---

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # 'echo' means R will print the code along with the results. 

rm(list = ls()) # clear workspace

library(terra)
library(sf)
library(dplyr)
library(stringr)
library(data.table)
library(tidyr)
library(viridis)
library(mapview)
library(raster)
library(lubridate)

source('./Code/CEMML/Misc/character_vectors.R')

```

# *PART ONE: User settings - choose AFB, model, scenarios, years of interest*

```{r set-directories}

dir_installation_boundaries <- "N:\\RStor\\mindyc\\afccm\\AF_CIP_ENV_Data_Phase3/Installation_Boundaries/" # site boundary shape files used for clipping

# The last two are straight from the original script. Will change so that directories can be set more generally in 'settings'

#dir_output_csvs = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Results_LOCA_V2" # output csv

#dir_functions = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Software Apps\\R scripts\\LOCA_V2" # scripts that call in functions for analysis
```



First, let's select which of the `models` you'd like to run. Highlight the word `models` and click 'Run' at the top right (or use the shortcut *Ctrl + Enter*). The available models correspond to numbers in the vector (e.g., HADGEM2-ES is [1]). 

In the code chunk below, enter the number between the brackets ([]) that corresponds with your model of interest. Then let's see what scenarios and variables are available for that model.

```{r enter-afb-and-model}

AFB_Name <- "Homestead_ARB" # Can create a vector similar to 'models' above if desired

model <- models[2] 

model_dir <- paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = "")
scenario_dirs <- list.dirs(path = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = ""), full.names = FALSE)

cat(paste("The model you have selected is", model, "and the AFB is", AFB_Name))

```

The next chunk checks what scenarios (subfolders) are contained in the 'Data' folder associated with the model of interest.

```{r results='asis'}

cat("The scenarios (subfolders) associated with this model are:", sep = '\n') # cat() basically means 'print' in this context 
cat(paste("-", scenario_dirs), sep = "\n") # names into separate lines for readability ('\n' = line)

```

*Enter the scenarios of interest below:*

```{r enter-scenarios}

scenario1 <- "historical"
scenario2 <- "rcp45"
scenario3 <- "rcp85"

```

Next, let's see which variables are represented in this dataset

```{r}

example_dir = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, "\\", scenario1, sep = "")
example_filenames <- list.files(example_dir, pattern = '.nc', full.names = FALSE) # this line might need to be adjusted if some files are .ncdf or other

variables <- unique(substr(example_filenames, 1,6)) # Numbers 1 and 6 refer to character indices within the file names (i.e., the first six letters of the file name)

cat("The variables in this dataset are:", sep = '\n')
cat(paste("-", variables), sep = "\n")

```

```{r enter-years-of-interest}

historical_start_year <- 1976 # Start year of interest for the historical time period  
historical_end_year <- 2005 # End year of interest for the historical time period

future1_start_year <- 2026 # Start year of interest for the first future time period 
future1_end_year <- 2035 # End year of interest for the first future time period 

future2_start_year <- 2046 # Start year of interest for the second future time period 
future2_end_year <- 2055 # End year of interest for the second future time period 

```

####################################################################################################
# THIS CONCLUDES THE USER SETTINGS PORTION OF THE SCRIPT

# PART TWO: SUBSET FILES OF INTEREST

You can double check the array here to make sure the years and scenarios are correct

```{r create-array}

scenarios <- c(scenario1, scenario2, scenario3)

scenario_yr_array = data.frame() # Maybe LOCA only?

scenario_yr_array[1,1:3] = c(scenario1, historical_start_year, historical_end_year)
scenario_yr_array[2,1:3] = c(scenario2, future1_start_year, future1_end_year)
scenario_yr_array[3,1:3] = c(scenario2, future2_start_year, future2_end_year)
scenario_yr_array[4,1:3] = c(scenario3, future1_start_year, future1_end_year)
scenario_yr_array[5,1:3] = c(scenario3, future2_start_year, future2_end_year)

colnames(scenario_yr_array) <- c("Scenario", "Start", "End")

scenario_yr_array

```


The next chunk checks that the spatial files are where they should be. The map will appear below the code chunk, and you can zoom in as needed to view small AFB's 

```{r pull-files-for-scenario1}

# Create stack for first scenario-year combo
  # This is done separately from the others for the sake of expediency. We need to view a single raster layer for our check,      but we don't want to spend time creating all the stacks if something is amiss 

s1_dir <- paste(model_dir, scenario1, sep = '\\')
s1v1_fileNames <- list.files(s1_dir, pattern = variables[1], full.names = TRUE) # s1 = scenario 1; v1 = variable 1
s1v1_years <- paste(seq(scenario_yr_array[1,2], scenario_yr_array[1,3], 1), collapse = "|") # partition by years of interest

dt <- data.table(s1v1_fileNames, result = grepl(s1v1_years, s1v1_fileNames))  # searches for filenames with the years of interest
dt <- dt %>% filter(result == TRUE) # spot check the number of observations - should equal the number of years in the time period of interest

s1v1_fileNames <- dt$s1v1_fileNames # turn data.frame column into a vector for use with rast(). Writes over earlier object with same name.

# Check printout below to make sure the first and last files look correct
first(s1v1_fileNames)
last(s1v1_fileNames)
```

# PART THREE: SPATIAL CHECK

```{r spatial-check}

# AFB

afb_dir <- (paste(dir_installation_boundaries, AFB_Name, sep = '/'))

afbSF <- st_read(paste(afb_dir, '.shp', sep = "")) # read in using sf package first
afbSF <- sf::st_as_sf(afbSF, coords = c("longitude", "latitude"), crs = st_crs(4326)) # EPSG:4326 is lat/long

afb <- vect(afbSF) # for use with terra package

# Raster

stackX <- rast(s1v1_fileNames)
rx <- raster(stackX[[1]]) # using raster package for example so can use with mapview (terra not supported)

# Quick plot

mapview(rx, col.regions = hcl.colors(5, palette = "viridis", alpha = 0.8)) + # First argument is arbitrary (# colors in palette)
  mapview(afbSF, col.regions = "black")

```

We need to check the size of the AFB to see whether we should use the centroid or multiple cells for analysis. 

```{r decision-to-use-shp-or-centroid-for-extraction, results='asis'}

# What is the cell size of the ncdf?

rx <- rast(rx) # convert to terra object because estimation is better. Could also use raster::area()
rxCrop <- terra::crop(rx, afb)
rxCell <- cellSize(rxCrop, unit = "km")
ncdf_cellSize <- mean(values(rxCell)) # get mean cell size of ncdf

# How big is the AFB?

afb_area <- expanse(afb, unit = "km")

centroid <- afbSF %>%
  st_centroid() %>%
  st_geometry() %>%
  st_coordinates()

# add an if_else statement to tell R whether to extract raster values from matrix or shapefile

extract_obj <- afb

extract_obj <- if(afb_area < ncdf_cellSize) centroid else (afb)

cat("The object used for data extraction is a", class(extract_obj)) # 'matrix array' = centroid; 'spatVector' = spatial object (multiple cells)

```


```{r extract-values}

# Create dataframe for extracted values

rTimes <- time(stackX)

v1 <- terra::extract(stackX, extract_obj)

results <- v1 %>%
  pivot_longer(cols = everything(),
               names_to = "Layer",
               names_prefix = variables[1],
               values_to = variables[1],
               values_drop_na = FALSE) 

results <- results %>%
  mutate(date = rTimes) %>%
  mutate(lon = centroid[1]) %>% # WILL NEED TO CHANGE ONCE WE USE A SPATIAL OBJECT TO EXTRACT DATA
  mutate(lat = centroid[2]) # WILL NEED TO CHANGE ONCE WE USE A SPATIAL OBJECT TO EXTRACT DATA

#saveRDS(results, file = './Results/temp.Rds')

```

```{r loop-for-all-files}

scenarios <- c(scenario1, scenario2, scenario3)
future1 <- paste(seq(future1_start_year, future1_end_year, 1), collapse = '|')
future2 <- paste(seq(future2_start_year, future2_end_year, 1), collapse = '|')

files_hist <- list()
files_future1 <- list()
files_future2 <- list()


# List remaining files for Historical

for(i in 2:length(variables)){ # start at 2 because already pulled s1v1
  fileNames = list.files(example_dir, pattern = variables[i], full.names = TRUE)
  dt = data.table(fileNames, result = grepl(hist_yrs, fileNames))
  dt2 = dplyr::filter(dt, result == TRUE)
  files_hist[[i]] = dt2$fileNames
}

# List files for Future 1

for(i in 1:length(variables)){ 
  dir = paste(model_dir, scenario2, sep = '\\')
  fileNames = list.files(dir, pattern = variables[i], full.names = TRUE)
  dt = data.table(fileNames, result = grepl(future1, fileNames))
  dt2 = dplyr::filter(dt, result == TRUE)
  files_future1[[i]] = dt2$fileNames
}

# List files for Future 2

for(i in 1:length(variables)){ 
  dir = paste(model_dir, scenario3, sep = '\\')
  fileNames = list.files(dir, pattern = variables[i], full.names = TRUE)
  dt = data.table(fileNames, result = grepl(future2, fileNames))
  dt2 = dplyr::filter(dt, result == TRUE)
  files_future2[[i]] = dt2$fileNames
}

```



```{r create-rasters}


piv2 <- pr_test %>%
  mutate(PPT_mm = pr*86400) # From RasterUnitConvert function

```

```{r unit-conversion}

```



```{r check-results}

# Bring in results 

avdf <- read_csv('./Results/allvaluesdf.Rds')


piv2$Compare <- results$PPT_mm

piv2$Diff <- piv2$PPT_mm - piv2$Compare

sum(piv2$Diff)

```












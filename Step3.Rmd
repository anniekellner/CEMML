---
title: "Step3_test"
author: "Annie Kellner"
date: "2023-02-07"
output: html_document
---

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # 'echo' means R will print the code along with the results. 

rm(list = ls()) # clear workspace

library(terra)
library(sf)
library(dplyr)
library(tmap)
library(tmaptools)
library(stringr)
library(data.table)
library(tidyr)
library(viridis)
library(mapview)
library(raster)

source('./Code/CEMML/Misc/character_vectors.R')

```

# *PART ONE: User settings - choose model, scenarios, years of interest*

First, let's select which of the `models` you'd like to run. Highlight the word `models` and click 'Run' at the top right (or use the shortcut *Ctrl + Enter*). The available models correspond to numbers in the vector (e.g., HADGEM2-ES is [1]). 

In the code chunk below, enter the number between the brackets ([]) that corresponds with your model of interest. Then let's see what variables are available for that model.

```{r select-model-and-check-variables}

model <- models[2]

# Using the 'historical' folder just to get a sample of filenames. If we need to change this strategy no biggie.

dir_historical_ncdfs = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, "\\historical", sep = "")

fileNames <- list.files(dir_historical_ncdfs, pattern = '.nc', full.names = FALSE)

variables <- unique(substr(fileNames, 1,7)) # Numbers 1 and 7 refer to character indexes within the file names (i.e., the first seven letters of the file names)

variables
```

Now we can see how the variables are labeled in this dataset, and we also have created a vector with their names. If you want to edit how they look, go ahead. It could be something like: 

```{r revise-variables}

variables <- c("pr", "tasmin", "tasmax")

```


```{r select AFB and years of interest}

AFB_Name <- "Homestead_ARB" # Can create a vector similar to 'models' above if desired

## Years of interest

historical_start_year <- 1976 # Start year of interest for the historical time period  
historical_end_year <- 2005 # End year of interest for the historical time period

future1_start_year <- 2026 # Start year of interest for the first future time period 
future1_end_year <- 2035 # End year of interest for the first future time period 

future2_start_year <- 2046 # Start year of interest for the second future time period 
future2_end_year <- 2055 # End year of interest for the second future time period 

```

# PART TWO: Let 'er Rip!


```{r directories, echo=FALSE}

dir_netcdfs = paste("N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Data\\", model, sep = "")

dir_installation_boundaries <- "N:\\RStor\\mindyc\\afccm\\AF_CIP_ENV_Data_Phase3/Installation_Boundaries/" # site boundary shape files used for clipping


# The last two are straight from the original script. Will change so that directories can be set more generally in 'settings'

#dir_output_csvs = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Results_LOCA_V2" # output csv

#dir_functions = "N:\\RStor\\mindyc\\afccm\\Climate Modeling\\Software Apps\\R scripts\\LOCA_V2" # scripts that call in functions for analysis

```

```{r create-array}

# Not sure if this only applies to LOCA, as comment implies. Can cross that bridge when we come to it. 

scenario_yr_array = array(1:15, dim=c(5,3))

scenario_yr_array[1,1:3] = c("historical", historical_start_year, historical_end_year)
scenario_yr_array[2,1:3] = c("rcp45", future1_start_year, future1_end_year)
scenario_yr_array[3,1:3] = c("rcp45", future2_start_year, future2_end_year)
scenario_yr_array[4,1:3] = c("rcp85", future1_start_year, future1_end_year)
scenario_yr_array[5,1:3] = c("rcp85", future2_start_year, future2_end_year)

```


```{r historical-files-variable1}

histFileNames_var1 <- list.files(dir_historical_ncdfs, pattern = variables[1], full.names = TRUE) # partition files by variable

pattern <- paste(seq(scenario_yr_array[1,2], scenario_yr_array[1,3], 1), collapse = "|") # partition by years of interest

DT <- data.table(histFileNames_var1, result = grepl(pattern, histFileNames_var1))  
histDT_var1 <- DT %>% filter(result == TRUE) # spot check the number of observations - should equal the number of years in the time period of interest

# Check to see that files look right and nothing weird made it into the list

#head(histDT_var1)
#tail(histDT_var1)

histFileNames_var1 <- histDT_var1$histFileNames_var1 # turn data.frame column into a vector for use with rast()

```

# *SPATIAL ANALYSIS*

First, let's do a gut check to make sure the spatial files are where they should be. The map will appear below the code chunk, and you can zoom in as needed to view small AFB's 

```{r gut-check-location}

# Rasters

rHistVar1 <- rast(histFileNames_var1) # multilayered raster for analysis

rx <- raster(rHistVar1[[1]]) # Single layer raster for plotting (first layer)

# AFB

afb_dir <- (paste(dir_installation_boundaries, AFB_Name, sep = '/'))

afbSF <- st_read(paste(afb_dir, '.shp', sep = "")) # read in using sf package first
afbSF <- sf::st_as_sf(afbSF, coords = c("longitude", "latitude"), crs = st_crs(4326)) # EPSG:4326 is lat/long

afb <- vect(afbSF) # for use with terra package

# Quick plot

mapview(rx, col.regions = hcl.colors(5, palette = "viridis", alpha = 0.8)) + # 5 i an ab
  mapview(afbSF, col.regions = "black")


```

We should also check the size of the AFB to see whether we should use the centroid or multiple cells for analysis. 

```{r}

# What is the cell size of the ncdf?

rx <- rast(rx) # convert to terra object because estimation is better. Could also use raster::area()
rxCrop <- terra::crop(rx, afb)
rxCell <- cellSize(rxCrop, unit = "km")
ncdf_cellSize <- mean(values(rxCell)) # get mean cell size of ncdf

# How big is the AFB?

afb_area <- expanse(afb, unit = "km")

```














